
const app = new Vue({
  el: "#app",
  vuetify: new Vuetify(),
  data: {
    textFromCamera: "",
    receptionistReply: null,        
    textUserSees: "",
    prevWord: "",
    repeatCount: 0
  },
  // As soon as reactive events are available
  created: function () {},
  // These are your functions
  methods: {
    passWords: function (words) {
      this.textFromCamera = words;
    },    
    checkText: function () {
      textArr = this.textFromCamera.split(" ")      
      textArr.pop()
      const currWord = textArr.pop()
      console.log(textArr)
      if (this.prevWord === currWord) {
        this.repeatCount += 1
      } else {
        this.repeatCount = 0
        this.prevWord = currWord        
      }
      if (this.repeatCount === 5) {
        this.textUserSees += " "
        this.textUserSees += currWord
      }
    },
    textToSpeech: function () {
      let speech = new SpeechSynthesisUtterance();
      speech.lang = "en";
      voices = window.speechSynthesis.getVoices();
      speech.voice = voices[67];
      speech.speed = 0.2;
      speech.pitch = 0.4;
      speech.text = this.receptionistReply;
      window.speechSynthesis.speak(speech);
    },
    teachableMachine: function (func) {
      // More API functions here:
      // https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/pose

      // the link to your model provided by Teachable Machine export panel
      const URL = "./my_model/";
      let model, webcam, ctx, labelContainer, maxPredictions;
      let words = "";
      let checker = "";
      let crossChecker = "";
      let counter = 0;
      init();

      async function init() {
        const modelURL = URL + "model.json";
        const metadataURL = URL + "metadata.json";

        // load the model and metadata
        // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
        // Note: the pose library adds a tmPose object to your window (window.tmPose)
        model = await tmPose.load(modelURL, metadataURL);
        maxPredictions = model.getTotalClasses();

        // Convenience function to setup a webcam
        const size = 400;
        const flip = true; // whether to flip the webcam
        webcam = new tmPose.Webcam(size, size, flip); // width, height, flip
        await webcam.setup(); // request access to the webcam
        await webcam.play();
        window.requestAnimationFrame(loop);

        // append/get elements to the DOM
        const canvas = document.getElementById("canvas");
        canvas.width = size;
        canvas.height = size;
        ctx = canvas.getContext("2d");
        labelContainer = document.getElementById("label-container");
        for (let i = 0; i < maxPredictions; i++) {
          // and class labels
          labelContainer.appendChild(document.createElement("div"));
        }
      }

      async function loop(timestamp) {
        webcam.update(); // update the webcam frame
        await predict();
        window.requestAnimationFrame(loop);
      }

      function withInterval(prediction, i, maxPredictions) {
        if (i < maxPredictions) {     
            var curr = prediction[i]     
            if (curr.probability > 0.9 
            && curr.className !=="Nothing" 
            && curr.className !=="Starter"                      
            ) {               
                words += curr.className + " ";           
                var audio = new Audio(curr.className+'.mp3');
                audio.play();
                chosen = true                   
            }            
            func(words);
            const res = () => null    
            res()
            console.log("Made it here")
            withInterval(prediction, i+1, maxPredictions)           
        }
      }

      async function predict() {
        // Prediction #1: run input through posenet
        // estimatePose can take in an image, video or canvas html element
        const { pose, posenetOutput } = await model.estimatePose(webcam.canvas);
        // Prediction 2: run input through teachable machine classification model
        const prediction = await model.predict(posenetOutput);

        for (let i = 0; i < maxPredictions; i++) {
          if(prediction[i].probability > 0.9 && words !== "" && prediction[i].className!=="stop" && prediction[i].className !== crossChecker && prediction[i].className!=="Hello.") {
              if(checker === "Hello.") {
                  counter ++;
                  console.log("checker: " + checker);
                  checker = prediction[i].className;
                  console.log("counter: " + counter);
                  console.log("current: "+prediction[i].className);
              } else {
                  if(prediction[i].className===checker) {
                      counter ++;
                      console.log("counter: " + counter);
                      if(counter >10) {
                          words = words + prediction[i].className+" ";
                          checker = "Hello.";
                          counter = 0;
                          crossChecker = prediction[i].className;
                          var audio = new Audio(prediction[i].className + ".mp3");
                          audio.play();
                          console.log("words: " + words);
                          console.log("crossChecker: " + crossChecker);
                      }
                  } else {
                    counter = 0;
                    checker = "Hello.";
                  }
              }
          } else if(prediction[i].probability > 0.9 && prediction[i].className==="Hello." && words === "") {
              words = words + prediction[i].className+" ";
              checker = prediction[i].className;
              var audio = new Audio(prediction[i].className + ".mp3");
              audio.play();
          } else if(prediction[i].probability > 0.9 && prediction[i].className==="stop") {
                  words = "";
                  checker = "";
                  crossChecker = "";
                  counter = 0;
          }
            func(words);
          }

        // finally draw the poses
        drawPose(pose);
      }

      function drawPose(pose) {
        if (webcam.canvas) {
          ctx.drawImage(webcam.canvas, 0, 0);
          // draw the keypoints and skeleton
          if (pose) {
            const minPartConfidence = 0.5;
            tmPose.drawKeypoints(pose.keypoints, minPartConfidence, ctx);
            tmPose.drawSkeleton(pose.keypoints, minPartConfidence, ctx);
          }
        }
      }
    },
  },

  // Watch for changes
  watch: {    
    textFromCamera: function () {
      this.checkText()
    }
  },
});

Vue.use(Vuetify);
